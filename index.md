---
layout: default
title: test2: Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing
---

<style>
/* Make the banner white */
.page-header {
  background-color: white !important;
}
.project-name,
.project-tagline {
  color: black !important;
}

/* Hide the "View on GitHub" button */
.github-corner {
  display: none !important;
}
</style>

# Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing

<!-- Embed a YouTube video -->
<iframe width="800" height="450" src="https://www.youtube.com/watch?v=zP4JvHaCWHk&t=11s" frameborder="0" allowfullscreen></iframe>

## Dataset

This section describes the dataset used in our experiments. The dataset consists of both simulated and real tactile data from various sensors.

## Method

Our method integrates tactile sensing with vision to improve grasping accuracy...

## Results

We demonstrate significant improvement in grasp success rates on real robot experiments.
